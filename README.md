# SF-AgentBench

**A Specialized Benchmarking Framework for Evaluating AI Agents on Salesforce Development**

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

---

## Overview

SF-AgentBench is a rigorous benchmarking framework designed to evaluate AI agentsâ€”such as Claude Code, Codex, or Gemini Orchestratorâ€”on their ability to design and build Salesforce solutions. While existing benchmarks like SWE-bench effectively assess code generation in file-based languages (Python, Java), they fail to capture the architectural complexity of Platform-as-a-Service (PaaS) environments like Salesforce.

Salesforce development is a hybrid practice requiring:
- **Declarative metadata** orchestration
- **Proprietary programming languages** (Apex, SOQL, LWC)
- **Stateful database interactions** within a multi-tenant environment
- **Strict execution limits** (Governor Limits)

SF-AgentBench addresses these unique challenges with a purpose-built evaluation framework.

## âœ¨ Features

### ğŸ–¥ï¸ Interactive Terminal UI

A beautiful, user-friendly terminal interface built with [Textual](https://textual.textualize.io/):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸš€ SF-AgentBench Dashboard                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚    5     â”‚ â”‚    2     â”‚ â”‚    2     â”‚ â”‚    1     â”‚            â”‚
â”‚  â”‚  Total   â”‚ â”‚  Tier 1  â”‚ â”‚  Tier 2  â”‚ â”‚  Tier 3  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  [Browse Tasks] [Run Benchmark] [View Results] [Configuration]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ D Dashboard â”‚ T Tasks â”‚ R Run â”‚ S Results â”‚ C Config â”‚ Q Quit   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**5 Interactive Screens:**
| Screen | Key | Description |
|--------|-----|-------------|
| Dashboard | `D` | Overview stats, quick actions, getting started |
| Tasks | `T` | Browse tasks by tier, view requirements |
| Run | `R` | Execute benchmarks with real-time progress |
| Results | `S` | Score history, layer breakdown, CSV export |
| Config | `C` | Edit all settings with tabbed interface |

### ğŸ¯ Curriculum-Aligned Evaluation

Grounded in official Salesforce certifications:
- **Administrator (ADM-201)** â€” Schema, automation, security
- **Platform Developer I & II (PD1/PD2)** â€” Apex, integrations, LWC

### ğŸ† Superbadge Methodology

Uses complex, scenario-based problem solving as the gold standardâ€”moving beyond atomic code generation to holistic solution architecture.

### ğŸ”§ Agent-Computer Interface (ACI)

11 tools wrapping the Salesforce CLI (`sf`) with structured JSON I/O:

| Tool | Description |
|------|-------------|
| `sf_deploy` | Deploy metadata to Scratch Org |
| `sf_retrieve` | Retrieve metadata from org |
| `sf_run_apex_tests` | Execute Apex tests with coverage |
| `sf_run_anonymous` | Run anonymous Apex code |
| `sf_query` | Execute SOQL queries |
| `sf_create_record` | Create sObject records |
| `sf_import_data` | Import data from plan files |
| `sf_scan_code` | Run PMD static analysis |
| `sf_org_create` | Create Scratch Orgs |
| `sf_org_delete` | Delete Scratch Orgs |
| `sf_org_open` | Get org login URL |

### ğŸ“Š 5-Layer Evaluation Pipeline

| Layer | Weight | Metric | Description |
|-------|--------|--------|-------------|
| **1** | 20% | Deployment | Can the solution deploy without errors? |
| **2** | 40% | Functional Tests | Do Apex tests pass? What's the coverage? |
| **3** | 10% | Static Analysis | Code quality via PMD/Code Analyzer |
| **4** | 15% | Metadata Diff | Semantic comparison against golden config |
| **5** | 15% | LLM Rubric | Design patterns, bulkification, best practices |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SF-AgentBench Harness                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Task      â”‚  â”‚   Agent     â”‚  â”‚      Evaluation         â”‚  â”‚
â”‚  â”‚   Loader    â”‚  â”‚   Runner    â”‚  â”‚      Pipeline           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Agent-Computer Interface (ACI)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚sf_deploy â”‚ â”‚sf_query  â”‚ â”‚sf_test   â”‚ â”‚sf_scan_code      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Salesforce CLI (sf)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Ephemeral Scratch Org Pool                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
sf-agentbench/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml              # Python package configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sf-agentbench.yaml          # Main configuration file
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ development/
â”‚       â”œâ”€â”€ Salesforce AI Benchmark Design.md
â”‚       â””â”€â”€ Salesforce AI Benchmark Design.pdf
â”œâ”€â”€ src/sf_agentbench/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                  # CLI entry point
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”œâ”€â”€ models.py               # Data models (Task, Result, etc.)
â”‚   â”œâ”€â”€ aci/                    # Agent-Computer Interface
â”‚   â”‚   â”œâ”€â”€ base.py             # Base tool class
â”‚   â”‚   â”œâ”€â”€ deploy.py           # sf_deploy, sf_retrieve
â”‚   â”‚   â”œâ”€â”€ apex.py             # sf_run_apex_tests, sf_run_anonymous
â”‚   â”‚   â”œâ”€â”€ data.py             # sf_query, sf_create_record, sf_import_data
â”‚   â”‚   â”œâ”€â”€ analysis.py         # sf_scan_code
â”‚   â”‚   â””â”€â”€ org.py              # Scratch org management
â”‚   â”œâ”€â”€ harness/                # Benchmark orchestration
â”‚   â”‚   â”œâ”€â”€ runner.py           # BenchmarkHarness
â”‚   â”‚   â”œâ”€â”€ task_loader.py      # Task discovery
â”‚   â”‚   â””â”€â”€ org_manager.py      # Scratch Org lifecycle
â”‚   â”œâ”€â”€ evaluators/             # 5-layer evaluation
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # Main pipeline
â”‚   â”‚   â”œâ”€â”€ deployment.py       # Layer 1
â”‚   â”‚   â”œâ”€â”€ functional.py       # Layer 2
â”‚   â”‚   â”œâ”€â”€ static_analysis.py  # Layer 3
â”‚   â”‚   â”œâ”€â”€ metadata_diff.py    # Layer 4
â”‚   â”‚   â””â”€â”€ rubric.py           # Layer 5
â”‚   â””â”€â”€ tui/                    # Terminal User Interface
â”‚       â”œâ”€â”€ app.py              # Main TUI application
â”‚       â””â”€â”€ screens/            # Dashboard, Tasks, Run, Results, Config
â”œâ”€â”€ tasks/                      # Benchmark tasks
â”‚   â”œâ”€â”€ tier-1/
â”‚   â””â”€â”€ tier-2/
â”œâ”€â”€ results/                    # Run outputs
â””â”€â”€ tests/                      # Test suite
```

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Salesforce CLI** (`sf`) â€” [Install Guide](https://developer.salesforce.com/tools/salesforcecli)
- **DevHub-enabled Org** â€” Required for Scratch Org creation

### Installation

```bash
# Clone the repository
git clone https://github.com/bhanudas/sf-agentbench.git
cd sf-agentbench

# Install in development mode
pip install -e .

# Initialize with sample tasks
sf-agentbench init
```

### Quick Start

#### Launch the Terminal UI (Recommended)

```bash
sf-agentbench-tui
```

Navigate with keyboard shortcuts:
- `D` - Dashboard
- `T` - Browse Tasks
- `R` - Run Benchmark
- `S` - View Results
- `C` - Configuration
- `Q` - Quit

#### Use the CLI

```bash
# List available tasks
sf-agentbench list-tasks

# Show task details
sf-agentbench show-task lead-scoring-validation

# Run a specific task
sf-agentbench run lead-scoring-validation --agent claude-code

# Validate your setup
sf-agentbench validate
```

## âš™ï¸ Configuration

Edit `sf-agentbench.yaml` to configure:

```yaml
# Agent configuration
agent:
  id: claude-code
  type: claude
  model: claude-sonnet-4-20250514
  api_key_env: ANTHROPIC_API_KEY

# Salesforce settings
devhub_username: admin@mydevhub.org

# Evaluation weights (must sum to 1.0)
evaluation_weights:
  deployment: 0.20
  functional_tests: 0.40
  static_analysis: 0.10
  metadata_diff: 0.15
  rubric: 0.15
```

## ğŸ“‹ Task Difficulty Tiers

| Tier | Complexity | Example | Skills Tested |
|------|------------|---------|---------------|
| **Tier 1** | Single-domain, declarative | Validation Rule + Flow | Schema, Validation Rules, Flows |
| **Tier 2** | Multi-domain, declarative + code | Screen Flow + Apex Action | Screen Flow, Invocable Apex, Testing |
| **Tier 3** | Complex code, async processing | Apex Specialist Superbadge | Triggers, Queueable, Bulkification |
| **Tier 4** | Full-stack, LWC, integrations | LWC Specialist Superbadge | LWC, Apex Services, Wire, Callouts |

## ğŸ“ˆ Scoring Methodology

The composite score combines all evaluation layers:

```
Final_Score = (
    0.20 Ã— deployment_success +
    0.40 Ã— apex_test_pass_rate +
    0.10 Ã— (1 - pmd_penalty) +
    0.15 Ã— metadata_accuracy +
    0.15 Ã— rubric_score
)
```

Score indicators:
- ğŸŸ¢ **Excellent**: â‰¥ 0.80
- ğŸŸ¡ **Good**: â‰¥ 0.60
- ğŸ”´ **Needs Work**: < 0.60

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation âœ…
- [x] ACI tool wrappers for core `sf` commands
- [x] Basic harness for task loading and evaluation
- [x] 5-layer evaluation pipeline
- [x] Terminal UI with Textual
- [x] Sample Tier 1 & 2 tasks

### Phase 2: Expansion
- [ ] DevHub setup with Scratch Org pool management
- [ ] PMD/Code Analyzer deep integration
- [ ] 10 Tier 3 tasks
- [ ] Baseline runs with leading AI agents

### Phase 3: Maturity
- [ ] LLM-as-a-Judge with multiple providers
- [ ] 5 Tier 4 tasks
- [ ] Public leaderboard
- [ ] Research paper submission

## ğŸ“š Documentation

- [Technical Design Document](docs/development/Salesforce%20AI%20Benchmark%20Design.md) â€” Comprehensive framework architecture and methodology

## ğŸ¤ Contributing

Contributions are welcome! Areas for contribution:
- New benchmark tasks (especially Tier 3 & 4)
- ACI tool enhancements
- Evaluation metric refinements
- Documentation improvements

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [SWE-bench](https://www.swebench.com/) and [SWE-agent](https://swe-agent.com/)
- Task methodology adapted from [Salesforce Trailhead Superbadges](https://trailhead.salesforce.com/superbadges)
- Built for the AI agent research community

---

<p align="center">
  <strong>SF-AgentBench</strong> â€” Bridging AI Agents and Enterprise Platform Development
</p>
